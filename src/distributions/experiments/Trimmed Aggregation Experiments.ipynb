{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Weighted) Kemeny Rank Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from itertools import combinations, permutations\n",
    "from typing import Optional\n",
    "import pickle as pkl\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from distributions import mallows_kendall as mk\n",
    "from distributions import permutil as pu\n",
    "from distributions import sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Impact of Noisy Rankings on Kemeny Rank Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "'N' : [10, 50], # Number of permutations\n",
    "'n' : [50, 100], # Number of items\n",
    "'theta': [0.05, 0.1, 0.2],\n",
    "'type': ['random', 'mixture'],\n",
    "'scale': [100],\n",
    "'noise': [0.0, 0.1, 0.25, 0.5],\n",
    "'seed': [0, 1, 2],\n",
    "}\n",
    "\n",
    "results = {}\n",
    "EXP_NUM = 1\n",
    "for parameters in tqdm(list(ParameterGrid(parameter_grid))):\n",
    "    ranks, _, _ = sampling.sample_mallows_with_noise(**parameters)\n",
    "    N, n = ranks.shape\n",
    "    true_rank = np.arange(n)\n",
    "    _, aggregated_rank = rank_aggregation.borda(ranks)\n",
    "    \n",
    "    results[str(EXP_NUM)] = {\n",
    "        'N' : parameters['N'],\n",
    "        'n' : parameters['n'],\n",
    "        'theta': parameters['theta'],\n",
    "        'type': parameters['type'],\n",
    "        'scale': parameters['scale'],\n",
    "        'noise': parameters['noise'],\n",
    "        'seed': parameters['seed'],\n",
    "        'Distance of Median from True Rank': mk.distance(aggregated_rank),\n",
    "        'NDCG of Median w.r.t. True Rank': ndcg_score(true_rank.reshape((1, -1)), aggregated_rank.reshape((1, -1))),\n",
    "    }\n",
    "    EXP_NUM = EXP_NUM + 1\n",
    "\n",
    "results = pd.DataFrame(results).T\n",
    "results.to_csv('experiments/impact_of_noise.csv', index=None)\n",
    "\n",
    "# View the results\n",
    "results = pd.read_csv('experiments/impact_of_noise.csv', index_col=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View some cases\n",
    "filtered_result = results.loc[(results['N'] == 50) & (results['n'] == 100) & (results['theta'] == 0.1)]\n",
    "\n",
    "for noise in [0.0, 0.1, 0.25, 0.5]:\n",
    "    print(f'Noise: {noise}')\n",
    "    print(filtered_result.loc[filtered_result['noise'] == noise].iloc[:, -2:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "params = {'text.usetex' : False,\n",
    "          'font.size' : 16,\n",
    "          \"font.family\": \"serif\",\n",
    "          \"font.serif\": [\"Palatino\"],\n",
    "          }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "noise = [str(i) for i in [0.0, 0.1, 0.25, 0.5]]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True, sharex=True)\n",
    "axes[0].bar(x=noise, height=[46.66, 46.66, 149.00, 326.16], width=0.5, color='darkblue')\n",
    "axes[0].set_title(r\"N = 50, n = 100, \\theta = 0.2\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Distance of Median from True Rank\", fontsize=16)\n",
    "axes[0].set_xlabel(\"Percentage of Noisy Samples\", fontsize=16)\n",
    "\n",
    "axes[1].bar(x=noise, height=[116.00, 151.00, 211.00, 396.66], width=0.5, color='darkblue')\n",
    "axes[1].set_title(r\"N = 50, n = 100, \\theta = 0.1\", fontsize=16)\n",
    "axes[1].set_xlabel(\"Percentage of Noisy Samples\", fontsize=16)\n",
    "\n",
    "axes[2].bar(x=noise, height=[247.33, 283.16, 346.50, 581.66], width=0.5, color='darkblue')\n",
    "axes[2].set_title(r\"N = 50, n = 100, \\theta = 0.05\", fontsize=16)\n",
    "axes[2].set_xlabel(\"Percentage of Noisy Samples\", fontsize=16)\n",
    "\n",
    "# fig.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "In models with strong concensus, the reliability of a metric is negatively correlated with the objective value i.e. if we remove a point which occurs under the model with low probability, then the objective results in a closely clustered value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "'m' : [10, 50], # Number of metrics\n",
    "'n' : [50, 100], # Number of models\n",
    "'theta' : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "ranking_data = {}\n",
    "std_dist_from_true_rank = []\n",
    "dist_of_median_from_true_rank = []\n",
    "for parameters in tqdm(list(ParameterGrid(parameter_grid))):\n",
    "    true_rank = np.arange(parameters['n'])\n",
    "    ranks = mk.sample(**parameters)\n",
    "    n_metrics, n_models = ranks.shape\n",
    "\n",
    "    objective_values = []\n",
    "    true_rank = np.arange(n_models)\n",
    "    distance_from_true_rank = [mk.distance(ranks[i, :], true_rank) for i in range(n_metrics-1, -1, -1)]\n",
    "    for idxs in combinations(np.arange(n_metrics), n_metrics-1):\n",
    "        borda_agg = mk.median(ranks[idxs, :])\n",
    "        objective_values.append(objective(borda_agg, ranks[idxs, :])/(n_metrics-1))\n",
    "    \n",
    "    print(kendalltau(objective_values, distance_from_true_rank))\n",
    "    print(spearmanr(objective_values, distance_from_true_rank))\n",
    "    \n",
    "    plt.scatter(objective_values, distance_from_true_rank)\n",
    "    plt.title(f\"# models = {n_models} # metrics = {n_metrics} theta = {parameters['theta']}\")\n",
    "    plt.xlabel('Average distance of median from samples')\n",
    "    plt.ylabel('Distance of excluded sample from true rank')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the Noisy Permutations\n",
    "\n",
    "X-axis (Average distance of median from samples) denotes the objective of the insample points i.e. average distance of the insample points from their median. \n",
    "Y-axis (Distance of excluded sample from true rank) denotes the average distance of the outsample points from the true rank (identity permutation). \n",
    "\n",
    "The highly negative correlation implies that excluding low-probability (outlying) points, improves the \"tightness\" of the inlying points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "'m' : [10, 50], # Number of metrics\n",
    "'n' : [50, 100], # Number of models\n",
    "'theta' : [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "NOISE = 0.1\n",
    "TOP_K = 0.95\n",
    "ranking_data = {}\n",
    "std_dist_from_true_rank = []\n",
    "dist_of_median_from_true_rank = []\n",
    "for parameters in tqdm(list(ParameterGrid(parameter_grid))):\n",
    "    true_rank = np.arange(parameters['n'])\n",
    "    ranks_mallow = mk.sample(**parameters)\n",
    "    ranks_random = sample_random(m=int(NOISE*parameters['m']), n=parameters['n'])\n",
    "    ranks = np.concatenate([ranks_mallow, ranks_random], axis=0)\n",
    "    \n",
    "    n_metrics, n_models = ranks.shape\n",
    "\n",
    "    objective_values = []\n",
    "    average_distance_of_outsample = []\n",
    "    true_rank = np.arange(n_models)\n",
    "    distance_from_true_rank = np.array([mk.distance(perm, true_rank) for perm in ranks])\n",
    "    n_insample_metrics = int(TOP_K*n_metrics)\n",
    "    \n",
    "    for idxs in combinations(np.arange(n_metrics), n_insample_metrics):\n",
    "        idxs_complement = np.setdiff1d(np.arange(n_metrics), idxs)\n",
    "        borda_agg = mk.median(ranks[idxs, :])\n",
    "        objective_values.append(objective(borda_agg, ranks[idxs, :])/(n_insample_metrics))\n",
    "        average_distance_of_outsample.append(np.mean(distance_from_true_rank[idxs_complement]))\n",
    "    \n",
    "    print(kendalltau(objective_values, average_distance_of_outsample))\n",
    "    print(spearmanr(objective_values, average_distance_of_outsample))\n",
    "    \n",
    "    plt.scatter(objective_values, average_distance_of_outsample)\n",
    "    plt.title(f\"# models = {n_models} # metrics = {n_metrics} theta = {parameters['theta']}\")\n",
    "    plt.xlabel('Average distance of median from samples')\n",
    "    plt.ylabel('Distance of excluded sample from true rank')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Reliability versus True Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distibutions.sampling import sample_mallows_with_noise\n",
    "from model_selection.rank_aggregation import borda, kemeny, trimmed_borda, trimmed_kemeny, influence, pagerank, proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'N' : 50, # Number of permutations\n",
    "    'n' : 100, # Number of items\n",
    "    'theta' : 0.2,\n",
    "    'noise': 0.5,\n",
    "    'type': 'mixture', \n",
    "    'seed': 0\n",
    "    } \n",
    "\n",
    "ranks, n_noisy, n_mallows = sample_mallows_with_noise(**parameters)\n",
    "N, n = ranks.shape\n",
    "true_rank = np.arange(n)\n",
    "\n",
    "_, borda_rank = borda(ranks, weights=None)\n",
    "borda_rank_dist = mk.distance(borda_rank)\n",
    "# print(borda_rank_dist)\n",
    "\n",
    "dist_from_true_rank = np.array([mk.distance(r) for r in ranks])\n",
    "# print(dist_from_true_rank)\n",
    "\n",
    "# Red -- Least probable data points\n",
    "# Blue -- Most probable data points\n",
    "colors = n_mallows*['darkblue']\n",
    "colors.extend(n_noisy*['red'])\n",
    "\n",
    "influence_of_ranks = influence(ranks, aggregation_type='borda')\n",
    "proximity_of_ranks = proximity(ranks)\n",
    "pagerank_of_ranks = pagerank(ranks)\n",
    "# print(influence_of_ranks, proximity_of_ranks, pagerank_of_ranks)\n",
    "plt.style.use('ggplot')\n",
    "figure, axis = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
    "figure.suptitle(f\"Anomaly Type: {parameters['type']}   Theta: {parameters['theta']}   Noise : {parameters['noise']}\", fontsize=16)\n",
    "axis[0].scatter(influence_of_ranks, dist_from_true_rank, c=colors, alpha=0.7)\n",
    "axis[0].set_xlabel('Influence of Permutation', fontsize=12)\n",
    "axis[0].set_ylabel('Distance from Central Permutation', fontsize=12)\n",
    "axis[1].scatter(proximity_of_ranks, dist_from_true_rank, c=colors, alpha=0.7)\n",
    "axis[1].set_xlabel('Proximity of Permutation', fontsize=12)\n",
    "# axis[1].set_ylabel('Distance from Central Permutation', fontsize=12)\n",
    "axis[2].scatter(pagerank_of_ranks, dist_from_true_rank, c=colors, alpha=0.7)\n",
    "axis[2].set_xlabel('Pagerank of Permutation', fontsize=12)\n",
    "# axis[2].set_ylabel('Distance from Central Permutation', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement due to Trimmed Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'N' : 50, # Number of permutations\n",
    "    'n' : 50, # Number of items\n",
    "    'theta' : 0.2,\n",
    "    'noise': 0.50,\n",
    "    'type': 'mixture', \n",
    "    'seed': 0\n",
    "    } \n",
    "\n",
    "TOP_K = int(0.5*parameters['N'])\n",
    "\n",
    "ranks, n_noisy, n_mallows = sample_mallows_with_noise(**parameters)\n",
    "N, n = ranks.shape\n",
    "true_rank = np.arange(n)\n",
    "\n",
    "_, borda_rank = borda(ranks, weights=None)\n",
    "borda_rank_dist = mk.distance(borda_rank)\n",
    "# print(borda_rank_dist)\n",
    "\n",
    "dist_from_true_rank = np.array([mk.distance(r) for r in ranks])\n",
    "# print(dist_from_true_rank)\n",
    "\n",
    "# Red -- Least probable data points\n",
    "# Blue -- Most probable data points\n",
    "colors = n_mallows*['darkblue']\n",
    "colors.extend(n_noisy*['red'])\n",
    "\n",
    "_, influence_trimmed_borda_rank = trimmed_borda(ranks, weights=None, top_k=TOP_K, aggregation_type='borda', metric='influence')\n",
    "influence_trimmed_borda_rank_dist = mk.distance(influence_trimmed_borda_rank)\n",
    "_, proximity_trimmed_borda_rank = trimmed_borda(ranks, weights=None, top_k=TOP_K, aggregation_type='borda', metric='proximity')\n",
    "proximity_trimmed_borda_rank_dist = mk.distance(proximity_trimmed_borda_rank)\n",
    "_, pagerank_trimmed_borda_rank = trimmed_borda(ranks, weights=None, top_k=TOP_K, aggregation_type='borda', metric='pagerank')\n",
    "pagerank_trimmed_borda_rank_dist = mk.distance(pagerank_trimmed_borda_rank)\n",
    "\n",
    "# print(influence_of_ranks, proximity_of_ranks, pagerank_of_ranks)\n",
    "print('Improvement in Distance from Central Permutation post Trimming')\n",
    "print('Influence', borda_rank_dist - influence_trimmed_borda_rank_dist)\n",
    "print('Proximity', borda_rank_dist - proximity_trimmed_borda_rank_dist)\n",
    "print('Pagerank', borda_rank_dist - pagerank_trimmed_borda_rank_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "497aa39221a2d595828a5630e1312db983d7ad61c3e1a02713fefe171df4cc42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
